{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71rP4yYDQLMe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/llama-fewshot.csv')\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akvbKWjRSela",
        "outputId": "d7b3a043-996a-47f7-abd6-40475d866edb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              Sentences  \\\n",
            "0     i went there lot of time with my friend in my ...   \n",
            "1     the temple was built at the time of perumthach...   \n",
            "2                                       tourists beware   \n",
            "3     however there are multiple other cafes in that...   \n",
            "4     the entry fee of rs 10 helps in some semblance...   \n",
            "...                                                 ...   \n",
            "1260  we had a lovely bath for 3 hours in lakkam sin...   \n",
            "1261          you can visit it if you are in fort kochi   \n",
            "1262  i went to this great shiva temple situated in ...   \n",
            "1263  honestly you will disappointed because this na...   \n",
            "1264                              worth your wallet too   \n",
            "\n",
            "                                            Predictions  \\\n",
            "0                                  ['school', 'family']   \n",
            "1     ['time', 'perumthachan', 'parayipetta panthiru...   \n",
            "2                                          ['tourists']   \n",
            "3                                     ['area', 'cafes']   \n",
            "4                                       ['cleanliness']   \n",
            "...                                                 ...   \n",
            "1260                      ['bath', 'lakkam', 'drizzle']   \n",
            "1261                                     ['fort kochi']   \n",
            "1262      ['Shiva temple', 'commercial hub', 'Trichur']   \n",
            "1263                             ['animals', 'nilgiri']   \n",
            "1264                                         ['wallet']   \n",
            "\n",
            "                            Labels  \n",
            "0                         ['null']  \n",
            "1                         ['null']  \n",
            "2                       ['beware']  \n",
            "3                             ['']  \n",
            "4     ['cleanliness', 'entry fee']  \n",
            "...                            ...  \n",
            "1260                      ['bath']  \n",
            "1261                          ['']  \n",
            "1262                      ['null']  \n",
            "1263                   ['animals']  \n",
            "1264                      ['null']  \n",
            "\n",
            "[1265 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(df['Labels'])):\n",
        "  if len(eval(df['Predictions'][i]))!=len(eval(df['Labels'][i])):\n",
        "    print\n",
        "    print(i)"
      ],
      "metadata": {
        "id": "096_tTPz8Qww",
        "outputId": "ff7e40e2-7b99-4ca2-80c7-2467213454c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "11\n",
            "15\n",
            "18\n",
            "19\n",
            "23\n",
            "24\n",
            "25\n",
            "31\n",
            "33\n",
            "37\n",
            "39\n",
            "41\n",
            "42\n",
            "44\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "55\n",
            "56\n",
            "57\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "68\n",
            "69\n",
            "70\n",
            "72\n",
            "73\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "92\n",
            "97\n",
            "99\n",
            "104\n",
            "106\n",
            "108\n",
            "109\n",
            "112\n",
            "113\n",
            "114\n",
            "117\n",
            "118\n",
            "119\n",
            "121\n",
            "122\n",
            "124\n",
            "125\n",
            "126\n",
            "129\n",
            "130\n",
            "131\n",
            "134\n",
            "135\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "146\n",
            "149\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "157\n",
            "158\n",
            "159\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "167\n",
            "169\n",
            "171\n",
            "172\n",
            "176\n",
            "178\n",
            "179\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "186\n",
            "187\n",
            "188\n",
            "191\n",
            "194\n",
            "196\n",
            "197\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "205\n",
            "207\n",
            "209\n",
            "211\n",
            "213\n",
            "216\n",
            "217\n",
            "219\n",
            "222\n",
            "223\n",
            "226\n",
            "232\n",
            "236\n",
            "237\n",
            "239\n",
            "241\n",
            "243\n",
            "244\n",
            "247\n",
            "248\n",
            "250\n",
            "251\n",
            "252\n",
            "254\n",
            "256\n",
            "257\n",
            "260\n",
            "262\n",
            "263\n",
            "267\n",
            "269\n",
            "272\n",
            "274\n",
            "276\n",
            "278\n",
            "279\n",
            "281\n",
            "282\n",
            "284\n",
            "285\n",
            "286\n",
            "287\n",
            "288\n",
            "289\n",
            "290\n",
            "292\n",
            "293\n",
            "295\n",
            "297\n",
            "299\n",
            "300\n",
            "301\n",
            "302\n",
            "303\n",
            "304\n",
            "305\n",
            "307\n",
            "308\n",
            "309\n",
            "310\n",
            "312\n",
            "314\n",
            "315\n",
            "316\n",
            "318\n",
            "319\n",
            "320\n",
            "321\n",
            "323\n",
            "324\n",
            "327\n",
            "329\n",
            "331\n",
            "332\n",
            "333\n",
            "334\n",
            "335\n",
            "336\n",
            "338\n",
            "339\n",
            "340\n",
            "343\n",
            "344\n",
            "346\n",
            "347\n",
            "348\n",
            "349\n",
            "350\n",
            "351\n",
            "352\n",
            "353\n",
            "357\n",
            "358\n",
            "359\n",
            "361\n",
            "362\n",
            "364\n",
            "368\n",
            "369\n",
            "372\n",
            "374\n",
            "376\n",
            "379\n",
            "380\n",
            "381\n",
            "382\n",
            "386\n",
            "388\n",
            "390\n",
            "391\n",
            "392\n",
            "393\n",
            "394\n",
            "395\n",
            "396\n",
            "397\n",
            "398\n",
            "400\n",
            "401\n",
            "402\n",
            "403\n",
            "404\n",
            "405\n",
            "408\n",
            "411\n",
            "412\n",
            "413\n",
            "415\n",
            "417\n",
            "421\n",
            "422\n",
            "423\n",
            "428\n",
            "432\n",
            "434\n",
            "437\n",
            "439\n",
            "441\n",
            "445\n",
            "446\n",
            "449\n",
            "450\n",
            "451\n",
            "452\n",
            "453\n",
            "457\n",
            "458\n",
            "459\n",
            "461\n",
            "462\n",
            "464\n",
            "465\n",
            "466\n",
            "467\n",
            "469\n",
            "470\n",
            "475\n",
            "477\n",
            "478\n",
            "479\n",
            "480\n",
            "482\n",
            "484\n",
            "486\n",
            "488\n",
            "489\n",
            "490\n",
            "491\n",
            "492\n",
            "493\n",
            "497\n",
            "498\n",
            "504\n",
            "507\n",
            "508\n",
            "509\n",
            "510\n",
            "511\n",
            "512\n",
            "513\n",
            "520\n",
            "522\n",
            "525\n",
            "526\n",
            "528\n",
            "529\n",
            "531\n",
            "532\n",
            "534\n",
            "538\n",
            "539\n",
            "540\n",
            "541\n",
            "544\n",
            "545\n",
            "548\n",
            "550\n",
            "552\n",
            "553\n",
            "554\n",
            "555\n",
            "556\n",
            "558\n",
            "559\n",
            "560\n",
            "561\n",
            "562\n",
            "564\n",
            "569\n",
            "570\n",
            "571\n",
            "572\n",
            "573\n",
            "574\n",
            "575\n",
            "576\n",
            "577\n",
            "581\n",
            "582\n",
            "583\n",
            "584\n",
            "586\n",
            "587\n",
            "589\n",
            "590\n",
            "591\n",
            "592\n",
            "593\n",
            "594\n",
            "595\n",
            "597\n",
            "598\n",
            "600\n",
            "603\n",
            "605\n",
            "608\n",
            "611\n",
            "613\n",
            "614\n",
            "616\n",
            "617\n",
            "619\n",
            "620\n",
            "623\n",
            "626\n",
            "627\n",
            "629\n",
            "631\n",
            "632\n",
            "633\n",
            "634\n",
            "635\n",
            "636\n",
            "638\n",
            "640\n",
            "641\n",
            "643\n",
            "644\n",
            "645\n",
            "647\n",
            "648\n",
            "650\n",
            "652\n",
            "653\n",
            "654\n",
            "655\n",
            "657\n",
            "658\n",
            "659\n",
            "661\n",
            "662\n",
            "668\n",
            "671\n",
            "673\n",
            "674\n",
            "675\n",
            "676\n",
            "677\n",
            "678\n",
            "680\n",
            "681\n",
            "682\n",
            "683\n",
            "684\n",
            "685\n",
            "686\n",
            "687\n",
            "688\n",
            "689\n",
            "690\n",
            "693\n",
            "695\n",
            "697\n",
            "701\n",
            "702\n",
            "703\n",
            "704\n",
            "705\n",
            "706\n",
            "708\n",
            "709\n",
            "710\n",
            "711\n",
            "712\n",
            "714\n",
            "715\n",
            "717\n",
            "719\n",
            "720\n",
            "722\n",
            "724\n",
            "726\n",
            "727\n",
            "728\n",
            "729\n",
            "732\n",
            "733\n",
            "734\n",
            "735\n",
            "737\n",
            "738\n",
            "739\n",
            "740\n",
            "741\n",
            "742\n",
            "743\n",
            "744\n",
            "747\n",
            "748\n",
            "749\n",
            "750\n",
            "752\n",
            "753\n",
            "754\n",
            "756\n",
            "757\n",
            "759\n",
            "761\n",
            "762\n",
            "763\n",
            "764\n",
            "765\n",
            "766\n",
            "767\n",
            "768\n",
            "769\n",
            "770\n",
            "772\n",
            "773\n",
            "775\n",
            "776\n",
            "777\n",
            "778\n",
            "779\n",
            "781\n",
            "782\n",
            "785\n",
            "786\n",
            "787\n",
            "788\n",
            "790\n",
            "791\n",
            "792\n",
            "793\n",
            "794\n",
            "795\n",
            "796\n",
            "797\n",
            "798\n",
            "799\n",
            "800\n",
            "801\n",
            "802\n",
            "805\n",
            "806\n",
            "808\n",
            "809\n",
            "810\n",
            "812\n",
            "813\n",
            "815\n",
            "820\n",
            "821\n",
            "825\n",
            "827\n",
            "828\n",
            "829\n",
            "830\n",
            "831\n",
            "832\n",
            "833\n",
            "835\n",
            "836\n",
            "838\n",
            "839\n",
            "840\n",
            "841\n",
            "842\n",
            "843\n",
            "845\n",
            "848\n",
            "850\n",
            "852\n",
            "854\n",
            "855\n",
            "858\n",
            "859\n",
            "860\n",
            "861\n",
            "864\n",
            "865\n",
            "866\n",
            "868\n",
            "874\n",
            "877\n",
            "878\n",
            "879\n",
            "880\n",
            "881\n",
            "882\n",
            "883\n",
            "884\n",
            "885\n",
            "888\n",
            "889\n",
            "890\n",
            "893\n",
            "894\n",
            "895\n",
            "896\n",
            "899\n",
            "901\n",
            "903\n",
            "905\n",
            "909\n",
            "911\n",
            "912\n",
            "914\n",
            "915\n",
            "916\n",
            "917\n",
            "918\n",
            "919\n",
            "921\n",
            "923\n",
            "924\n",
            "925\n",
            "926\n",
            "928\n",
            "930\n",
            "931\n",
            "932\n",
            "933\n",
            "934\n",
            "938\n",
            "939\n",
            "940\n",
            "941\n",
            "945\n",
            "946\n",
            "947\n",
            "949\n",
            "951\n",
            "952\n",
            "954\n",
            "956\n",
            "957\n",
            "958\n",
            "959\n",
            "960\n",
            "961\n",
            "962\n",
            "963\n",
            "966\n",
            "968\n",
            "969\n",
            "970\n",
            "973\n",
            "974\n",
            "977\n",
            "978\n",
            "980\n",
            "981\n",
            "983\n",
            "984\n",
            "985\n",
            "986\n",
            "987\n",
            "988\n",
            "989\n",
            "991\n",
            "996\n",
            "998\n",
            "1000\n",
            "1002\n",
            "1003\n",
            "1006\n",
            "1008\n",
            "1009\n",
            "1010\n",
            "1011\n",
            "1012\n",
            "1013\n",
            "1014\n",
            "1016\n",
            "1018\n",
            "1019\n",
            "1020\n",
            "1022\n",
            "1023\n",
            "1024\n",
            "1025\n",
            "1026\n",
            "1027\n",
            "1028\n",
            "1029\n",
            "1032\n",
            "1033\n",
            "1034\n",
            "1035\n",
            "1037\n",
            "1039\n",
            "1040\n",
            "1041\n",
            "1042\n",
            "1043\n",
            "1044\n",
            "1046\n",
            "1047\n",
            "1048\n",
            "1049\n",
            "1050\n",
            "1051\n",
            "1052\n",
            "1054\n",
            "1055\n",
            "1057\n",
            "1059\n",
            "1061\n",
            "1062\n",
            "1069\n",
            "1070\n",
            "1071\n",
            "1072\n",
            "1073\n",
            "1074\n",
            "1075\n",
            "1076\n",
            "1077\n",
            "1078\n",
            "1079\n",
            "1080\n",
            "1083\n",
            "1085\n",
            "1087\n",
            "1088\n",
            "1091\n",
            "1092\n",
            "1094\n",
            "1097\n",
            "1098\n",
            "1099\n",
            "1100\n",
            "1106\n",
            "1108\n",
            "1109\n",
            "1110\n",
            "1112\n",
            "1113\n",
            "1114\n",
            "1116\n",
            "1117\n",
            "1118\n",
            "1121\n",
            "1123\n",
            "1124\n",
            "1127\n",
            "1129\n",
            "1131\n",
            "1133\n",
            "1134\n",
            "1137\n",
            "1139\n",
            "1141\n",
            "1142\n",
            "1147\n",
            "1148\n",
            "1150\n",
            "1151\n",
            "1152\n",
            "1153\n",
            "1156\n",
            "1159\n",
            "1160\n",
            "1161\n",
            "1164\n",
            "1166\n",
            "1167\n",
            "1168\n",
            "1169\n",
            "1170\n",
            "1171\n",
            "1172\n",
            "1173\n",
            "1174\n",
            "1175\n",
            "1176\n",
            "1177\n",
            "1180\n",
            "1186\n",
            "1192\n",
            "1194\n",
            "1195\n",
            "1196\n",
            "1197\n",
            "1200\n",
            "1201\n",
            "1202\n",
            "1203\n",
            "1204\n",
            "1205\n",
            "1206\n",
            "1207\n",
            "1208\n",
            "1210\n",
            "1211\n",
            "1212\n",
            "1214\n",
            "1216\n",
            "1217\n",
            "1219\n",
            "1220\n",
            "1221\n",
            "1223\n",
            "1224\n",
            "1226\n",
            "1229\n",
            "1230\n",
            "1231\n",
            "1232\n",
            "1233\n",
            "1235\n",
            "1236\n",
            "1240\n",
            "1241\n",
            "1243\n",
            "1244\n",
            "1246\n",
            "1247\n",
            "1249\n",
            "1250\n",
            "1251\n",
            "1252\n",
            "1253\n",
            "1255\n",
            "1256\n",
            "1257\n",
            "1260\n",
            "1262\n",
            "1263\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_labels(sentence, aspect_terms):\n",
        "    words = sentence.strip().split()\n",
        "    labels = ['O'] * len(words)\n",
        "\n",
        "    for aspect_term in eval(aspect_terms):\n",
        "        aspect_term=aspect_term.lower()\n",
        "        aspect_words = aspect_term.split()\n",
        "        if aspect_words and aspect_words[0] in words:\n",
        "            start_index = words.index(aspect_words[0])\n",
        "            labels[start_index] = 'B'\n",
        "            for i in range(1, len(aspect_words)):\n",
        "                if start_index + i < len(words) and words[start_index + i] == aspect_words[i]:\n",
        "                    labels[start_index + i] = 'I'\n",
        "\n",
        "\n",
        "    return labels"
      ],
      "metadata": {
        "id": "O0IXQ4g0hPdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_list=[]\n",
        "for i in range(len(df)):\n",
        "  labels = extract_labels(df['Sentences'][i], df['Predictions'][i])\n",
        "  predictions_list.append(labels)"
      ],
      "metadata": {
        "id": "DoFWWJXIhQl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Single Aspect Term"
      ],
      "metadata": {
        "id": "R2S_xh1UUiZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "true_positive=0\n",
        "false_positive=0\n",
        "true_negative=0\n",
        "false_negative=0"
      ],
      "metadata": {
        "id": "U9UHZVhmSs4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''predictions_list=[]\n",
        "for i in df['Predictions']:\n",
        "  predictions_list.append(eval(i))'''"
      ],
      "metadata": {
        "id": "AMlO8hi_UWM3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "0619aab6-8be9-4763-f4d4-d1d95bd6fd49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"predictions_list=[]\\nfor i in df['Predictions']:\\n  predictions_list.append(eval(i))\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "true_df=pd.read_csv('/content/new_final_test_data_with_null.csv')\n",
        "labels_list=[]\n",
        "for i in true_df['Labels']:\n",
        "  labels_list.append(eval(i))"
      ],
      "metadata": {
        "id": "GMQxsXfGVOiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(labels_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xku-Yo5zgob4",
        "outputId": "6b47996a-02cc-4b5d-f33d-c9dc5419c687"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1265"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predictions_list[278])\n",
        "print(labels_list[278])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfE71wrJb3lL",
        "outputId": "b8b4d191-b2cf-4bb1-9812-1434000da76b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def extract_aspect_terms(labels):\n",
        "    single_word_terms = []\n",
        "    double_word_terms = []\n",
        "    triple_word_terms = []\n",
        "    multi_word_terms = []\n",
        "\n",
        "    i = 0\n",
        "    while i < len(labels):\n",
        "        if labels[i] == 'B':\n",
        "            if i + 1 < len(labels) and labels[i + 1] == 'I':\n",
        "                if i + 2 < len(labels) and labels[i + 2] == 'I':\n",
        "                    # Triple or multi-word term\n",
        "                    j = i + 3\n",
        "                    while j < len(labels) and labels[j] == 'I':\n",
        "                        j += 1\n",
        "                    if j == i + 3:\n",
        "                        triple_word_terms.append((i, j))\n",
        "                    else:\n",
        "                        multi_word_terms.append((i, j))\n",
        "                    i = j\n",
        "                else:\n",
        "                    double_word_terms.append((i, i + 2))\n",
        "                    i += 2\n",
        "            else:\n",
        "                single_word_terms.append((i, i + 1))\n",
        "                i += 1\n",
        "        else:\n",
        "            i += 1\n",
        "    return single_word_terms, double_word_terms, triple_word_terms, multi_word_terms\n",
        "\n",
        "def calculate_tp_fp_fn(true_terms, pred_terms):\n",
        "    tp = len(set(pred_terms) & set(true_terms))\n",
        "    fp = len(set(pred_terms) - set(true_terms))\n",
        "    fn = len(set(true_terms) - set(pred_terms))\n",
        "    return tp, fp, fn\n",
        "\n",
        "def calculate_metrics(labels_list, predictions_list):\n",
        "    single_tp, single_fp, single_fn = 0, 0, 0\n",
        "    double_tp, double_fp, double_fn = 0, 0, 0\n",
        "    triple_tp, triple_fp, triple_fn = 0, 0, 0\n",
        "    multi_tp, multi_fp, multi_fn = 0, 0, 0\n",
        "\n",
        "    single_total, double_total, triple_total, multi_total = 0, 0, 0, 0\n",
        "\n",
        "    for labels, predictions in zip(labels_list, predictions_list):\n",
        "        # Extract aspect terms from ground truth and predictions\n",
        "        true_single, true_double, true_triple, true_multi = extract_aspect_terms(labels)\n",
        "        pred_single, pred_double, pred_triple, pred_multi = extract_aspect_terms(predictions)\n",
        "\n",
        "        # Calculate TP, FP, FN for each type of aspect term\n",
        "        s_tp, s_fp, s_fn = calculate_tp_fp_fn(true_single, pred_single)\n",
        "        d_tp, d_fp, d_fn = calculate_tp_fp_fn(true_double, pred_double)\n",
        "        t_tp, t_fp, t_fn = calculate_tp_fp_fn(true_triple, pred_triple)\n",
        "        m_tp, m_fp, m_fn = calculate_tp_fp_fn(true_multi, pred_multi)\n",
        "\n",
        "        # Sum up the TP, FP, FN\n",
        "        single_tp += s_tp\n",
        "        single_fp += s_fp\n",
        "        single_fn += s_fn\n",
        "\n",
        "        double_tp += d_tp\n",
        "        double_fp += d_fp\n",
        "        double_fn += d_fn\n",
        "\n",
        "        triple_tp += t_tp\n",
        "        triple_fp += t_fp\n",
        "        triple_fn += t_fn\n",
        "\n",
        "        multi_tp += m_tp\n",
        "        multi_fp += m_fp\n",
        "        multi_fn += m_fn\n",
        "\n",
        "        # Calculate True Negatives for 'O' labels\n",
        "        single_total += len(true_single)\n",
        "        double_total += len(true_double)\n",
        "        triple_total += len(true_triple)\n",
        "        multi_total += len(true_multi)\n",
        "\n",
        "    # Calculate metrics\n",
        "    def calculate_prf1(tp, fp, fn, total):\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "        accuracy = tp / total if total > 0 else 0\n",
        "        return precision, recall, f1_score, accuracy\n",
        "\n",
        "    single_precision, single_recall, single_f1, single_accuracy = calculate_prf1(single_tp, single_fp, single_fn, single_total)\n",
        "    double_precision, double_recall, double_f1, double_accuracy = calculate_prf1(double_tp, double_fp, double_fn, double_total)\n",
        "    triple_precision, triple_recall, triple_f1, triple_accuracy = calculate_prf1(triple_tp, triple_fp, triple_fn, triple_total)\n",
        "    multi_precision, multi_recall, multi_f1, multi_accuracy = calculate_prf1(multi_tp, multi_fp, multi_fn, multi_total)\n",
        "\n",
        "    metrics = {\n",
        "        \"Aspect Term Type\": [\"Single Word\", \"Double Word\", \"Triple Word\"],\n",
        "        \"TP\": [single_tp, double_tp, triple_tp],\n",
        "        \"FP\": [single_fp, double_fp, triple_fp],\n",
        "        \"FN\": [single_fn, double_fn, triple_fn],\n",
        "        \"Total number of Apect Terms\": [single_total, double_total, triple_total],\n",
        "        \"Precision\": [single_precision, double_precision, triple_precision],\n",
        "        \"Recall\": [single_recall, double_recall, triple_recall],\n",
        "        \"F1-Score\": [single_f1, double_f1, triple_f1],\n",
        "        \"Accuracy\": [single_accuracy, double_accuracy, triple_accuracy]\n",
        "    }\n",
        "\n",
        "    df_metrics = pd.DataFrame(metrics)\n",
        "    return df_metrics\n",
        "\n",
        "\n",
        "# Calculate and print metrics\n",
        "metrics_df = calculate_metrics(labels_list, predictions_list)\n",
        "print(metrics_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gHz_x7S4haD",
        "outputId": "2b4af71f-db34-4fac-8534-afdde00bca5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Aspect Term Type   TP    FP   FN  Total number of Apect Terms  Precision  \\\n",
            "0      Single Word  510  1332  422                          932   0.276873   \n",
            "1      Double Word  185   449  137                          322   0.291798   \n",
            "2      Triple Word   17    78   38                           55   0.178947   \n",
            "\n",
            "     Recall  F1-Score  Accuracy  \n",
            "0  0.547210  0.367700  0.547210  \n",
            "1  0.574534  0.387029  0.574534  \n",
            "2  0.309091  0.226667  0.309091  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "y_true_flat = [label for sublist in labels_list for label in sublist]\n",
        "y_pred_flat = [label for sublist in predictions_list for label in sublist]\n",
        "\n",
        "accuracy = accuracy_score(y_true_flat, y_pred_flat)\n",
        "\n",
        "report = classification_report(y_true_flat, y_pred_flat)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74ejCXSQgUZD",
        "outputId": "12c9126f-bfc4-44b0-f63f-fddfeb19e860"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8102015188662322\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       0.30      0.58      0.39      1344\n",
            "           I       0.28      0.47      0.35       561\n",
            "           O       0.95      0.84      0.89     14818\n",
            "\n",
            "    accuracy                           0.81     16723\n",
            "   macro avg       0.51      0.63      0.55     16723\n",
            "weighted avg       0.87      0.81      0.83     16723\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def extract_aspect_terms(labels):\n",
        "    single_word_terms = []\n",
        "    double_word_terms = []\n",
        "    triple_word_terms = []\n",
        "    multi_word_terms = []\n",
        "\n",
        "    i = 0\n",
        "    while i < len(labels):\n",
        "        if labels[i] == 'B':\n",
        "            if i + 1 < len(labels) and labels[i + 1] == 'I':\n",
        "                if i + 2 < len(labels) and labels[i + 2] == 'I':\n",
        "                    # Triple or multi-word term\n",
        "                    j = i + 3\n",
        "                    while j < len(labels) and labels[j] == 'I':\n",
        "                        j += 1\n",
        "                    if j == i + 3:\n",
        "                        triple_word_terms.append((i, j))\n",
        "                    else:\n",
        "                        multi_word_terms.append((i, j))\n",
        "                    i = j\n",
        "                else:\n",
        "                    double_word_terms.append((i, i + 2))\n",
        "                    i += 2\n",
        "            else:\n",
        "                single_word_terms.append((i, i + 1))\n",
        "                i += 1\n",
        "        else:\n",
        "            i += 1\n",
        "    return single_word_terms, double_word_terms, triple_word_terms, multi_word_terms\n",
        "\n",
        "def calculate_tp_fp_fn(true_terms, pred_terms):\n",
        "    tp = len(set(pred_terms) & set(true_terms))\n",
        "    fp = len(set(pred_terms) - set(true_terms))\n",
        "    fn = len(set(true_terms) - set(pred_terms))\n",
        "    return tp, fp, fn\n",
        "\n",
        "def calculate_metrics(labels_list, predictions_list):\n",
        "    single_tp, single_fp, single_fn = 0, 0, 0\n",
        "    double_tp, double_fp, double_fn = 0, 0, 0\n",
        "    triple_tp, triple_fp, triple_fn = 0, 0, 0\n",
        "    multi_tp, multi_fp, multi_fn = 0, 0, 0\n",
        "\n",
        "    single_total, double_total, triple_total, multi_total = 0, 0, 0, 0\n",
        "\n",
        "    for labels, predictions in zip(labels_list, predictions_list):\n",
        "        # Extract aspect terms from ground truth and predictions\n",
        "        true_single, true_double, true_triple, true_multi = extract_aspect_terms(labels)\n",
        "        pred_single, pred_double, pred_triple, pred_multi = extract_aspect_terms(predictions)\n",
        "\n",
        "        # Calculate TP, FP, FN for each type of aspect term\n",
        "        s_tp, s_fp, s_fn = calculate_tp_fp_fn(true_single, pred_single)\n",
        "        d_tp, d_fp, d_fn = calculate_tp_fp_fn(true_double, pred_double)\n",
        "        t_tp, t_fp, t_fn = calculate_tp_fp_fn(true_triple, pred_triple)\n",
        "        m_tp, m_fp, m_fn = calculate_tp_fp_fn(true_multi, pred_multi)\n",
        "\n",
        "        # Sum up the TP, FP, FN\n",
        "        single_tp += s_tp\n",
        "        single_fp += s_fp\n",
        "        single_fn += s_fn\n",
        "\n",
        "        double_tp += d_tp\n",
        "        double_fp += d_fp\n",
        "        double_fn += d_fn\n",
        "\n",
        "        triple_tp += t_tp\n",
        "        triple_fp += t_fp\n",
        "        triple_fn += t_fn\n",
        "\n",
        "        multi_tp += m_tp\n",
        "        multi_fp += m_fp\n",
        "        multi_fn += m_fn\n",
        "\n",
        "        # Calculate True Negatives for 'O' labels\n",
        "        single_total += len(true_single)\n",
        "        double_total += len(true_double)\n",
        "        triple_total += len(true_triple)\n",
        "        multi_total += len(true_multi)\n",
        "\n",
        "    # Calculate metrics\n",
        "    def calculate_prf1(tp, fp, fn, total):\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "        accuracy = tp / total if total > 0 else 0\n",
        "        return precision, recall, f1_score, accuracy\n",
        "\n",
        "    single_precision, single_recall, single_f1, single_accuracy = calculate_prf1(single_tp, single_fp, single_fn, single_total)\n",
        "    double_precision, double_recall, double_f1, double_accuracy = calculate_prf1(double_tp, double_fp, double_fn, double_total)\n",
        "    triple_precision, triple_recall, triple_f1, triple_accuracy = calculate_prf1(triple_tp, triple_fp, triple_fn, triple_total)\n",
        "    multi_precision, multi_recall, multi_f1, multi_accuracy = calculate_prf1(multi_tp, multi_fp, multi_fn, multi_total)\n",
        "\n",
        "    metrics = {\n",
        "        \"Aspect Term Type\": [\"Single Word\", \"Double Word\", \"Triple Word\", \"Multi Word\"],\n",
        "        \"TP\": [single_tp, double_tp, triple_tp, multi_tp],\n",
        "        \"FP\": [single_fp, double_fp, triple_fp, multi_fp],\n",
        "        \"FN\": [single_fn, double_fn, triple_fn, multi_fn],\n",
        "        \"Total\": [single_total, double_total, triple_total, multi_total],\n",
        "        \"Precision\": [single_precision, double_precision, triple_precision, multi_precision],\n",
        "        \"Recall\": [single_recall, double_recall, triple_recall, multi_recall],\n",
        "        \"F1-Score\": [single_f1, double_f1, triple_f1, multi_f1],\n",
        "        \"Accuracy\": [single_accuracy, double_accuracy, triple_accuracy, multi_accuracy]\n",
        "    }\n",
        "\n",
        "    df_metrics = pd.DataFrame(metrics)\n",
        "    return df_metrics\n",
        "\n",
        "# Example input lists\n",
        "labels_list = [\n",
        "    ['O', 'B', 'I', 'O', 'B', 'O', 'O', 'B', 'I', 'I', 'O'],\n",
        "    ['O', 'O', 'B', 'I', 'O', 'B', 'I', 'I', 'O', 'O', 'O']\n",
        "]\n",
        "predictions_list = [\n",
        "    ['O', 'B', 'O', 'O', 'B', 'O', 'O', 'B', 'I', 'O', 'O'],\n",
        "    ['O', 'O', 'B', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O']\n",
        "]\n",
        "\n",
        "# Calculate and print metrics\n",
        "metrics_df = calculate_metrics(labels_list, predictions_list)\n",
        "print(metrics_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hi1rM0sIYN6S",
        "outputId": "91080a22-c2e2-4540-9c2f-b1d49bf3697d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Aspect Term Type  TP  FP  FN  Total  Precision  Recall  F1-Score  Accuracy\n",
            "0      Single Word   1   1   0      1   0.500000     1.0  0.666667       1.0\n",
            "1      Double Word   1   2   1      2   0.333333     0.5  0.400000       0.5\n",
            "2      Triple Word   0   0   2      2   0.000000     0.0  0.000000       0.0\n",
            "3       Multi Word   0   0   0      0   0.000000     0.0  0.000000       0.0\n"
          ]
        }
      ]
    }
  ]
}